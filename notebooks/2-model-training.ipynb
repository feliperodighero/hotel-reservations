{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5da83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import (AdaBoostClassifier,\n",
    "                              BaggingClassifier,\n",
    "                              ExtraTreesClassifier,\n",
    "                              GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             f1_score,\n",
    "                             roc_auc_score)\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18331771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/external/Hotel Reservations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf817261",
   "metadata": {},
   "source": [
    "# ðŸ‡ºðŸ‡¸ Modeling Data - ðŸ‡§ðŸ‡· Modelando os Dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb05fbf",
   "metadata": {},
   "source": [
    "## Label Encoder\n",
    "\n",
    "ðŸ‡ºðŸ‡¸ Label Encoding is a data preprocessing technique that converts categorical values (such as text or labels) into numerical values. This is useful because most machine learning algorithms require numerical input to work properly.\n",
    "\n",
    "ðŸ‡§ðŸ‡· O Label Encoding Ã© uma tÃ©cnica de prÃ©-processamento de dados que converte valores categÃ³ricos (como textos ou rÃ³tulos) em valores numÃ©ricos. Isso Ã© Ãºtil porque a maioria dos algoritmos de machine learning requer dados numÃ©ricos para funcionar corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fea01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "for col in ['type_of_meal_plan', 'room_type_reserved', 'market_segment_type', 'booking_status']:\n",
    "    df[col] = label_encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794017e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['booking_status', 'Booking_ID'], axis=1)\n",
    "y = df['booking_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26583ee",
   "metadata": {},
   "source": [
    "## Over Sample\n",
    "\n",
    "ðŸ‡ºðŸ‡¸ Over Sampling is a technique used to deal with imbalanced datasets, where one class has significantly fewer examples than the other. This imbalance can hurt the performance of machine learning models, as they tend to favor the majority class.\n",
    "The idea of Over Sampling is to increase the number of samples from the minority class, either by duplicating existing samples or by generating new synthetic ones (such as with the SMOTE algorithm), until both classes are more balanced. This helps the model learn patterns from both classes and improves its ability to generalize.\n",
    "\n",
    "ðŸ‡§ðŸ‡· O Over Sampling (ou superamostragem) Ã© uma tÃ©cnica usada para lidar com conjuntos de dados desbalanceados, onde uma das classes possui muito menos exemplos do que a outra. Esse desequilÃ­brio pode prejudicar o desempenho de modelos de machine learning, pois eles tendem a favorecer a classe majoritÃ¡ria.\n",
    "Com o Over Sampling, a ideia Ã© aumentar a quantidade de exemplos da classe minoritÃ¡ria, gerando cÃ³pias ou criando novos exemplos sintÃ©ticos (como com o algoritmo SMOTE), atÃ© que haja um equilÃ­brio entre as classes. Isso ajuda o modelo a aprender melhor os padrÃµes das duas classes e melhorar sua capacidade de generalizaÃ§Ã£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a79eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=42)\n",
    "over_X, over_y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658b5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_X_train, over_X_test, over_y_train, over_y_test = train_test_split(\n",
    "    over_X, over_y, test_size=0.2, stratify=over_y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ecabcb",
   "metadata": {},
   "source": [
    "## Standard Scaler\n",
    "\n",
    "ðŸ‡ºðŸ‡¸ Standard Scaler is a normalization technique that transforms the data so that it has a mean of 0 and a standard deviation of 1. This is done by subtracting the mean and dividing by the standard deviation for each numeric column.\n",
    "This scaling is important because many machine learning algorithms (such as logistic regression, SVM, KNN, and neural networks) are sensitive to the scale of the data. By applying the Standard Scaler, we ensure that all variables contribute equally during training, preventing variables with larger values from dominating the learning process.\n",
    "\n",
    "ðŸ‡§ðŸ‡· O Standard Scaler Ã© uma tÃ©cnica de normalizaÃ§Ã£o que transforma os dados para que tenham mÃ©dia igual a 0 e desvio padrÃ£o igual a 1. Isso Ã© feito subtraindo a mÃ©dia e dividindo pelo desvio padrÃ£o de cada coluna numÃ©rica.\n",
    "Essa padronizaÃ§Ã£o Ã© importante porque muitos algoritmos de machine learning (como regressÃ£o logÃ­stica, SVM, KNN e redes neurais) sÃ£o sensÃ­veis Ã  escala dos dados. Ao aplicar o Standard Scaler, garantimos que todas as variÃ¡veis tenham o mesmo peso na hora de treinar o modelo, evitando que variÃ¡veis com valores maiores dominem o aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae78a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "over_X_train = scaler.fit_transform(over_X_train)\n",
    "over_X_test = scaler.transform(over_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd954b",
   "metadata": {},
   "source": [
    "## Training Models - Treinando os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244fd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    AdaBoostClassifier(random_state=ord(\"S\")),\n",
    "    BaggingClassifier(random_state=ord(\"S\")),\n",
    "    DecisionTreeClassifier(random_state=ord(\"S\")),\n",
    "    ExtraTreesClassifier(random_state=ord(\"S\")),\n",
    "    GradientBoostingClassifier(random_state=ord(\"S\")),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(random_state=ord(\"S\")),\n",
    "    XGBClassifier(random_state=ord(\"S\"), use_label_encoder=False, eval_metric='logloss'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_models(models, over_X_train, over_y_train, over_X_test, over_y_test):\n",
    "    results = []\n",
    "\n",
    "    for model in models:\n",
    "        start = time.time()\n",
    "\n",
    "        cv_results = cross_validate(\n",
    "            model,\n",
    "            over_X_train,\n",
    "            over_y_train,\n",
    "            cv=5,\n",
    "            scoring=['accuracy', 'f1', 'roc_auc'],\n",
    "            return_train_score=True\n",
    "        )\n",
    "\n",
    "        train_mean_accuracy = cv_results['train_accuracy'].mean()\n",
    "        train_mean_roc_auc = cv_results['train_roc_auc'].mean()\n",
    "        train_mean_f1 = cv_results['train_f1'].mean()\n",
    "\n",
    "        model.fit(over_X_train, over_y_train)\n",
    "        test_preds = model.predict(over_X_test)\n",
    "\n",
    "        test_accuracy = accuracy_score(over_y_test, test_preds)\n",
    "        test_roc_auc = roc_auc_score(over_y_test, test_preds)\n",
    "        test_f1 = f1_score(over_y_test, test_preds)\n",
    "\n",
    "        results_dict = {\n",
    "            'model': model.__class__.__name__,\n",
    "            'train_accuracy': train_mean_accuracy,\n",
    "            'train_roc_auc': train_mean_roc_auc,\n",
    "            'train_f1': train_mean_f1,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'test_roc_auc': test_roc_auc,\n",
    "            'test_f1': test_f1,\n",
    "            'time_taken': time.time() - start\n",
    "        }\n",
    "        results.append(results_dict)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.set_index('model', inplace=True)\n",
    "    results_df = results_df.sort_values(by='test_accuracy', ascending=False)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00db7e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/FelipePessoal/Developer/URI/topicos-especiais/hotel-reservations/hotel_reservations/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/FelipePessoal/Developer/URI/topicos-especiais/hotel-reservations/hotel_reservations/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:39:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/FelipePessoal/Developer/URI/topicos-especiais/hotel-reservations/hotel_reservations/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:39:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/FelipePessoal/Developer/URI/topicos-especiais/hotel-reservations/hotel_reservations/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:39:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/FelipePessoal/Developer/URI/topicos-especiais/hotel-reservations/hotel_reservations/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:39:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/FelipePessoal/Developer/URI/topicos-especiais/hotel-reservations/hotel_reservations/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:39:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "results_df = training_models(models, over_X_train, over_y_train, over_X_test, over_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd98bdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.994651</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.994651</td>\n",
       "      <td>0.924559</td>\n",
       "      <td>0.924559</td>\n",
       "      <td>0.925203</td>\n",
       "      <td>13.717675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.994657</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.916052</td>\n",
       "      <td>0.916052</td>\n",
       "      <td>0.916198</td>\n",
       "      <td>13.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.989103</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.989079</td>\n",
       "      <td>0.910722</td>\n",
       "      <td>0.910722</td>\n",
       "      <td>0.909956</td>\n",
       "      <td>3.489235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.925751</td>\n",
       "      <td>0.981741</td>\n",
       "      <td>0.926044</td>\n",
       "      <td>0.906724</td>\n",
       "      <td>0.906724</td>\n",
       "      <td>0.907520</td>\n",
       "      <td>2.039286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.994657</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.891554</td>\n",
       "      <td>0.891554</td>\n",
       "      <td>0.891175</td>\n",
       "      <td>0.486065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.899844</td>\n",
       "      <td>0.969980</td>\n",
       "      <td>0.899642</td>\n",
       "      <td>0.867159</td>\n",
       "      <td>0.867159</td>\n",
       "      <td>0.866226</td>\n",
       "      <td>4.975628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.840143</td>\n",
       "      <td>0.925602</td>\n",
       "      <td>0.840736</td>\n",
       "      <td>0.841533</td>\n",
       "      <td>0.841533</td>\n",
       "      <td>0.842148</td>\n",
       "      <td>12.096769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.780334</td>\n",
       "      <td>0.874430</td>\n",
       "      <td>0.784235</td>\n",
       "      <td>0.784338</td>\n",
       "      <td>0.784338</td>\n",
       "      <td>0.787432</td>\n",
       "      <td>2.908717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            train_accuracy  train_roc_auc  train_f1  \\\n",
       "model                                                                 \n",
       "RandomForestClassifier            0.994651       0.999545  0.994651   \n",
       "ExtraTreesClassifier              0.994657       0.999922  0.994652   \n",
       "BaggingClassifier                 0.989103       0.999167  0.989079   \n",
       "XGBClassifier                     0.925751       0.981741  0.926044   \n",
       "DecisionTreeClassifier            0.994657       0.999922  0.994652   \n",
       "KNeighborsClassifier              0.899844       0.969980  0.899642   \n",
       "GradientBoostingClassifier        0.840143       0.925602  0.840736   \n",
       "AdaBoostClassifier                0.780334       0.874430  0.784235   \n",
       "\n",
       "                            test_accuracy  test_roc_auc   test_f1  time_taken  \n",
       "model                                                                          \n",
       "RandomForestClassifier           0.924559      0.924559  0.925203   13.717675  \n",
       "ExtraTreesClassifier             0.916052      0.916052  0.916198   13.014593  \n",
       "BaggingClassifier                0.910722      0.910722  0.909956    3.489235  \n",
       "XGBClassifier                    0.906724      0.906724  0.907520    2.039286  \n",
       "DecisionTreeClassifier           0.891554      0.891554  0.891175    0.486065  \n",
       "KNeighborsClassifier             0.867159      0.867159  0.866226    4.975628  \n",
       "GradientBoostingClassifier       0.841533      0.841533  0.842148   12.096769  \n",
       "AdaBoostClassifier               0.784338      0.784338  0.787432    2.908717  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc15d3b",
   "metadata": {},
   "source": [
    "# ðŸ‡ºðŸ‡¸ Tuning Models - ðŸ‡§ðŸ‡· Tunando Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52ae15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
